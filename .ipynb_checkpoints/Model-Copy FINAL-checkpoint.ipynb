{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import quandl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from datetime import datetime as dt, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    # Login details: \n",
    "    DSN_Name = 'traderDSN' ; Login_ID = 'basic' ; pwd = 'pwd1'\n",
    "\n",
    "    # The engine does the same job as a connection and a cursor\n",
    "    engine = create_engine(r'mssql+pyodbc://'+Login_ID+':'+pwd+'@'+ DSN_Name) \n",
    "\n",
    "    return engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine and query \n",
    "engine = create_connection()\n",
    "query = ''' \n",
    "SELECT * FROM {schema}.{table_name}\n",
    "'''.format(schema='stocks', table_name='Adjusted_Fortune_500')\n",
    "\n",
    "# Importing a Pandas Dataframe\n",
    "prices = pd.read_sql(query,engine)\n",
    "prices = prices.drop(columns=['index','close', 'split coefficient','dividend amount'])\n",
    "prices = prices.rename(columns={'Ticker':'symbol','adjusted close':'close','Name':'name'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat column types\n",
    "prices['open']  = prices['open'].astype(float)\n",
    "prices['high']  = prices['high'].astype(float)\n",
    "prices['low']   = prices['low'].astype(float)\n",
    "prices['close'] = prices['close'].astype(float)\n",
    "prices['volume']= prices['volume'].astype(float)\n",
    "prices['date'] = pd.to_datetime(prices['date'])\n",
    "\n",
    "# Create and sort indexes\n",
    "prices.set_index(['name', 'symbol', 'date'], inplace=True)\n",
    "prices = prices.sort_index(level=1, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated columns\n",
    "prices  = prices.copy().loc[(prices.loc[:,'open':'volume'] != 0 ).all(axis=1)] # Don't touch this (:\n",
    "\n",
    "# Group over the symbols. \n",
    "prices_g = prices.groupby(level=['name'])\n",
    "\n",
    "# Calculate many moving averages, of closing prices\n",
    "EMA_lengths = [20, 50, 200]  \n",
    "for l in EMA_lengths: \n",
    "    prices['EMA_'+str(l)] = prices_g.close.apply(lambda x: ta.EMA(x,l))   \n",
    "\n",
    "prices['EMA_ratio'] = prices['EMA_200']/prices['EMA_50'] # Ratio of moving average\n",
    "prices['RSI'] = prices_g.close.apply(lambda x: ta.RSI(x, 14))  # 14 day relative strength index\n",
    "\n",
    "def CCI_func(x):\n",
    "    xh = x.high \n",
    "    xl = x.low \n",
    "    xc = x.close \n",
    "    return ta.CCI(high=xh, low=xl, close=xc, timeperiod=5)\n",
    "\n",
    "prices['CCI'] = prices_g.apply(CCI_func).reset_index(level=0,).drop(columns='name')    # created an extra column. \n",
    "\n",
    "prices['Momentum'] = prices_g.close.apply(lambda x: ta.MOM(x, 10))  # 10 day rolling momentum changed to prices_g.close\n",
    "\n",
    "def Stoch_fast(x, index):\n",
    "    xh = x.high \n",
    "    xl = x.low \n",
    "    xc = x.close \n",
    "    return ta.STOCHF(high=xh, low=xl, close=xc, fastk_period=14, fastd_period=3)[index] # Params 14, 3    \n",
    "\n",
    "#prices['Stoch_fastk'] = prices_g.apply(Stoch_fast, 0).reset_index(level=1,).drop(columns='symbol')   # Stochastic fast indicator\n",
    "#prices['Stoch_fastd'] = prices_g.apply(Stoch_fast, 1).reset_index(level=1,).drop(columns='symbol')\n",
    "\n",
    "# def OBV_func(x):\n",
    "#    xc = x.close\n",
    "#     xv = x.volume\n",
    "#    return ta.OBV(xc, xv) \n",
    "#prices['OBV'] = prices_g.apply(OBV_func).reset_index(level=1,).drop(columns='symbol')  # On Balance Volume\n",
    "\n",
    "\n",
    "def bband_func(x, index):\n",
    "    xc = x.close\n",
    "    return ta.BBANDS(xc)[index]\n",
    "\n",
    "prices['bbandupper'] = prices_g.apply(bband_func, 0).reset_index(level=0,).drop(columns='name')\n",
    "prices['bbandmiddle'] = prices_g.apply(bband_func, 1).reset_index(level=0,).drop(columns='name') \n",
    "prices['bbandlower'] =  prices_g.apply(bband_func, 2).reset_index(level=0,).drop(columns='name')\n",
    "\n",
    "# Standadises bands\n",
    "prices['bbandlowerii'] =  prices['bbandlower']/prices['close']\n",
    "prices['bbandupperii'] =  prices['bbandupper']/prices['close']\n",
    "\n",
    "# Create target column\n",
    "prices['5_day_target'] = prices.groupby(['name'])['close'].transform(lambda x:x.shift(-5))\n",
    "prices['perc_change']=prices['5_day_target']/prices['close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import treasury yield data\n",
    "US_yields=quandl.get(\"USTREASURY/YIELD\", authtoken=\"wdLjKc5NXiuwUhFLByKm\")\n",
    "US_yields=US_yields[['3 MO', '6 MO', '1 YR', '2 YR', '3 YR', '5 YR', '7 YR', '10 YR', '30 YR']]\n",
    "US_yields.index.rename('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join prices and treasury data\n",
    "prices.reset_index(level='date',inplace=True)\n",
    "test=pd.merge(prices, US_yields, how='left', left_on='date' , right_index=True)\n",
    "test.set_index('date',append=True,inplace=True)\n",
    "test.sort_index(level=1, ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-calculated data\n",
    "merged = test.copy().loc[(test.loc[:,'open':'30 YR'] != 0 ).all(axis=1)]\n",
    "merged.drop(columns=['30 YR'], inplace=True)\n",
    "merged.fillna(method='pad', inplace=True)\n",
    "clean_prices = merged.loc[(merged['EMA_200'].notnull() & merged['5_day_target'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganise columns\n",
    "clean_prices=clean_prices.loc[:,[\n",
    "'open',\n",
    "'high',\n",
    "'low',\n",
    "'close',\n",
    "'volume',\n",
    "'EMA_20',\n",
    "'EMA_50',\n",
    "'EMA_200',\n",
    "'bbandupper',\n",
    "'bbandmiddle',\n",
    "'bbandlower',\n",
    "'EMA_ratio',\n",
    "'RSI',\n",
    "'CCI',\n",
    "'Momentum',\n",
    "#'Stoch_fastk',\n",
    "#'Stoch_fastd',\n",
    "#'OBV',\n",
    "'bbandlowerii',\n",
    "'bbandupperii',\n",
    "'3 MO',\n",
    "'6 MO',\n",
    "'1 YR',\n",
    "'2 YR',\n",
    "'3 YR',\n",
    "'5 YR',\n",
    "'7 YR',\n",
    "'10 YR',\n",
    "'5_day_target',\n",
    "'perc_change']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set test size per stock\n",
    "test_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = clean_prices.copy().loc[:,'EMA_ratio':'10 YR'] \n",
    "y = clean_prices.copy().loc[:, ['perc_change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get series of ingroup rownumbers\n",
    "X['num']= X.groupby(level=1).cumcount(ascending=False)\n",
    "\n",
    "# Use num to split train/test by date\n",
    "X_train = X.loc[X.num > test_size ].drop(columns='num')\n",
    "X_test =  X.loc[X.num <= test_size ].drop(columns='num')\n",
    "y_train = y.loc[X.num > test_size ]\n",
    "y_test =  y.loc[X.num <= test_size ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train machine learning\n",
    "forest = RandomForestRegressor()\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test results\n",
    "y_pred = forest.predict(X_test)\n",
    "y_pred = pd.DataFrame({'ans': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.282156106552661"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-squared value\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract current data\n",
    "predict_days=clean_prices.sort_index(level=1, ascending=True).groupby(['name']).tail(1).loc[:,'EMA_ratio':'10 YR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_days['5dayforecast'] = forest.predict(predict_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=predict_days.join(merged, lsuffix='l',how ='left')[['close','5dayforecast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['5day_price']=result['close']*result['5dayforecast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['5day%_change']=(result['5dayforecast']-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## May be useful in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "prep = result[['close','5day_price','5day%_change']]\n",
    "prep.sort_values(\"5day%_change\",ascending=False, inplace=True)\n",
    "prep.reset_index(inplace=True)\n",
    "prep.set_index('name')\n",
    "tdf=timedelta(days=5)\n",
    "prep=prep[prep['date']>=(dt.now()-tdf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling for Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.to_pickle('top_movers.pkl')\n",
    "clean_prices.to_pickle('clean_prices.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
